{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning\n",
    "\n",
    "A deep neural network (multilayer perceptron, MLP) will be used to classify audio recordings as either urban or natural environments. The following plans have been made:\n",
    "\n",
    "1. I will use the BayesianOptimization hyperparameter tuning procedure to search for the best depth of the model, number of units at each layer, learning rate, and activation function.\n",
    "2. To avoid overfitting, a dropout layer will be inserted between any two layers, and the dropout rate will also be tuned.\n",
    "3. Since pre-trained CNN models such as VGGish, YAMNet, and PANNs may represent similar information, I will only use the embeddings of one model at a time, along with features of soundscape indices and the spectrotemporal modulation spectrum.\n",
    "4. I will train a deep neural network on the features of each of the raw, background (bg), and foreground (fg) signals, as well as on the joint features of these three signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Code Functionality Breakdown**\n",
    "\n",
    "#### **1. Purpose of the Code**\n",
    "This code implements the **training and evaluation pipeline** for a **speech emotion recognition model** using selected features (e.g., MPS, YAMNet, VGGish, Acoustic Indices). It employs **Keras Tuner** to optimize hyperparameters and evaluate the model's performance using classification metrics and visualizations.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Key Components**\n",
    "\n",
    "#### **2.1 `ModelConfig`**\n",
    "This dataclass defines the configuration for the model:\n",
    "- **General Parameters:**\n",
    "  - `num_classes`: Number of emotion classes (7 in this case).\n",
    "  - `patience`: Early stopping patience.\n",
    "  - `max_trials`: Maximum trials for hyperparameter tuning.\n",
    "  - `max_epochs`: Maximum training epochs.\n",
    "  - `batch_size`: Batch size during training.\n",
    "- **Feature Selection:**\n",
    "  - Flags (`use_indices`, `use_mps`, etc.) to enable/disable specific features.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2.2 `EmotionRecognitionModel` Class**\n",
    "The main class orchestrating the workflow for model training, tuning, and evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Class Methods**\n",
    "\n",
    "#### **3.1 Initialization**\n",
    "- **Attributes:**\n",
    "  - `data_path`: Path to the aggregated `.pkl` file containing PCA-transformed features and labels.\n",
    "  - `output_dir`: Directory to store model files and plots.\n",
    "  - `label_mapping`: Maps emotion names (e.g., \"anger\") to integer labels.\n",
    "\n",
    "#### **3.2 Data Loading and Preprocessing**\n",
    "- **`load_and_preprocess_data`:**\n",
    "  - Loads features and labels from the aggregated `.pkl` file.\n",
    "  - Combines selected features based on the flags in `ModelConfig`.\n",
    "  - Processes emotion labels using `label_mapping`.\n",
    "  - Ensures that data lengths match and features are finite.\n",
    "\n",
    "#### **3.3 Model Building**\n",
    "- **`build_model`:**\n",
    "  - Builds a sequential neural network with:\n",
    "    - Input layer with dropout and batch normalization.\n",
    "    - Configurable number of dense hidden layers (`num_layers`) with varying units, activation functions, and dropout rates.\n",
    "    - Output layer with softmax activation for classification.\n",
    "  - Compiles the model with:\n",
    "    - Sparse categorical cross-entropy as the loss.\n",
    "    - Accuracy as the evaluation metric.\n",
    "    - Adam optimizer with tunable learning rate.\n",
    "\n",
    "#### **3.4 Callbacks**\n",
    "- **`create_callbacks`:**\n",
    "  - Includes:\n",
    "    - Early stopping to avoid overfitting.\n",
    "    - Model checkpointing to save the best model during training.\n",
    "    - ReduceLROnPlateau to adjust the learning rate when validation loss stagnates.\n",
    "    - CSVLogger to log training metrics for each epoch.\n",
    "\n",
    "#### **3.5 Training and Hyperparameter Tuning**\n",
    "- **`train_and_evaluate`:**\n",
    "  - **Hyperparameter Search:** Uses Keras Tuner's `BayesianOptimization` to find the best hyperparameters.\n",
    "  - **Training:** Fits the model on the training set using the best hyperparameters.\n",
    "  - **Evaluation:** Evaluates the model on the test set and generates metrics and plots.\n",
    "\n",
    "#### **3.6 Evaluation**\n",
    "- **`_evaluate_model`:**\n",
    "  - Evaluates the model on the test set, logs the accuracy, and generates:\n",
    "    - **Training History Plot:** Accuracy and loss over epochs.\n",
    "    - **Confusion Matrix:** Visualization of true vs. predicted labels.\n",
    "    - **Classification Report:** Precision, recall, and F1-score for each class.\n",
    "\n",
    "- **`_plot_training_history`:** Creates accuracy and loss plots for training and validation.\n",
    "- **`_plot_confusion_matrix`:** Generates a confusion matrix heatmap with annotations.\n",
    "\n",
    "#### **3.7 Saving Model Configuration**\n",
    "- **`_save_model_config`:**\n",
    "  - Saves the model architecture and hyperparameters to a text file for reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Workflow**\n",
    "\n",
    "#### **4.1 Main Function**\n",
    "- Configures feature usage and hyperparameters using `ModelConfig`.\n",
    "- Initializes `EmotionRecognitionModel`.\n",
    "- Executes `train_and_evaluate` to complete the training and evaluation workflow.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Outputs**\n",
    "\n",
    "1. **Model and Hyperparameters:**\n",
    "   - Best model saved as `best_model.keras` (or `final_model.keras` for the final trained model).\n",
    "   - Model configuration and hyperparameters saved in `model_config.txt`.\n",
    "\n",
    "2. **Metrics and Reports:**\n",
    "   - Classification report with precision, recall, and F1-score for all emotion classes.\n",
    "   - Test accuracy logged.\n",
    "\n",
    "3. **Visualizations:**\n",
    "   - **Training History:** Accuracy and loss plots.\n",
    "   - **Confusion Matrix:** Annotated heatmap showing classification performance.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Role in Your Project**\n",
    "This code is the **final stage** of your speech emotion recognition pipeline:\n",
    "1. **Uses Preprocessed Features:** Combines PCA-transformed features (e.g., MPS, YAMNet) as inputs.\n",
    "2. **Hyperparameter Tuning:** Optimizes the model's architecture and learning rate using Bayesian optimization.\n",
    "3. **Model Training:** Trains the model on the training set with early stopping and adaptive learning rate adjustments.\n",
    "4. **Evaluation:** Generates metrics and visualizations to assess performance.\n",
    "\n",
    "Let me know if you need clarifications or modifications to this code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 17:28:54,573 - INFO - Best hyperparameters: {'num_layers': 2, 'units_0': 64, 'activation': 'tanh', 'dropout_0': 0.048025717537726054, 'lr': 0.003982481621996575, 'units_1': 96, 'dropout_1': 0.03913898423227741, 'units_2': 112, 'dropout_2': 0.10396428308681199, 'units_3': 480, 'dropout_3': 0.11056798437483073, 'units_4': 256, 'dropout_4': 0.22641850754909082}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 05s]\n",
      "val_accuracy: 0.8317757248878479\n",
      "\n",
      "Best val_accuracy So Far: 0.8598130941390991\n",
      "Total elapsed time: 00h 01m 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.2415 - loss: 3.7959 - val_accuracy: 0.7103 - val_loss: 2.8116 - learning_rate: 0.0040\n",
      "Epoch 2/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6843 - loss: 2.5523 - val_accuracy: 0.7383 - val_loss: 2.4748 - learning_rate: 0.0040\n",
      "Epoch 3/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8545 - loss: 2.0248 - val_accuracy: 0.7664 - val_loss: 2.2059 - learning_rate: 0.0040\n",
      "Epoch 4/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 1.7688 - val_accuracy: 0.7570 - val_loss: 1.9934 - learning_rate: 0.0040\n",
      "Epoch 5/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 1.6152 - val_accuracy: 0.7757 - val_loss: 1.8177 - learning_rate: 0.0040\n",
      "Epoch 6/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 1.3929 - val_accuracy: 0.7757 - val_loss: 1.7082 - learning_rate: 0.0040\n",
      "Epoch 7/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9442 - loss: 1.2828 - val_accuracy: 0.7570 - val_loss: 1.6359 - learning_rate: 0.0040\n",
      "Epoch 8/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 1.1563 - val_accuracy: 0.7664 - val_loss: 1.5650 - learning_rate: 0.0040\n",
      "Epoch 9/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 1.0611 - val_accuracy: 0.7009 - val_loss: 1.5009 - learning_rate: 0.0040\n",
      "Epoch 10/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.9913 - val_accuracy: 0.7850 - val_loss: 1.3942 - learning_rate: 0.0040\n",
      "Epoch 11/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.8990 - val_accuracy: 0.7850 - val_loss: 1.3448 - learning_rate: 0.0040\n",
      "Epoch 12/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.8382 - val_accuracy: 0.7944 - val_loss: 1.2566 - learning_rate: 0.0040\n",
      "Epoch 13/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9434 - loss: 0.8093 - val_accuracy: 0.8224 - val_loss: 1.2425 - learning_rate: 0.0040\n",
      "Epoch 14/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.7223 - val_accuracy: 0.7757 - val_loss: 1.3102 - learning_rate: 0.0040\n",
      "Epoch 15/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9338 - loss: 0.7649 - val_accuracy: 0.7757 - val_loss: 1.3094 - learning_rate: 0.0040\n",
      "Epoch 16/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.6913 - val_accuracy: 0.7570 - val_loss: 1.2383 - learning_rate: 0.0040\n",
      "Epoch 17/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9530 - loss: 0.6733 - val_accuracy: 0.7664 - val_loss: 1.1400 - learning_rate: 0.0040\n",
      "Epoch 18/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.7303 - val_accuracy: 0.7664 - val_loss: 1.1927 - learning_rate: 0.0040\n",
      "Epoch 19/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.6176 - val_accuracy: 0.7757 - val_loss: 1.2165 - learning_rate: 0.0040\n",
      "Epoch 20/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 0.6219 - val_accuracy: 0.7570 - val_loss: 1.2131 - learning_rate: 0.0040\n",
      "Epoch 21/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.5934 - val_accuracy: 0.7850 - val_loss: 1.0786 - learning_rate: 0.0020\n",
      "Epoch 22/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.5890 - val_accuracy: 0.8037 - val_loss: 1.0528 - learning_rate: 0.0020\n",
      "Epoch 23/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.5206 - val_accuracy: 0.7944 - val_loss: 1.0718 - learning_rate: 0.0020\n",
      "Epoch 24/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.5360 - val_accuracy: 0.7850 - val_loss: 1.0592 - learning_rate: 0.0020\n",
      "Epoch 25/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9706 - loss: 0.4543 - val_accuracy: 0.7664 - val_loss: 1.0723 - learning_rate: 0.0020\n",
      "Epoch 26/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.4932 - val_accuracy: 0.7850 - val_loss: 1.0709 - learning_rate: 9.9562e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.4447 - val_accuracy: 0.8037 - val_loss: 1.0724 - learning_rate: 9.9562e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.4645 - val_accuracy: 0.7757 - val_loss: 1.0579 - learning_rate: 9.9562e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9869 - loss: 0.4110 - val_accuracy: 0.7664 - val_loss: 1.0490 - learning_rate: 4.9781e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.3944 - val_accuracy: 0.7664 - val_loss: 1.0424 - learning_rate: 4.9781e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.4291 - val_accuracy: 0.7850 - val_loss: 1.0353 - learning_rate: 4.9781e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.3951 - val_accuracy: 0.7850 - val_loss: 1.0298 - learning_rate: 4.9781e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.4419 - val_accuracy: 0.7850 - val_loss: 1.0286 - learning_rate: 4.9781e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.3749 - val_accuracy: 0.7850 - val_loss: 1.0238 - learning_rate: 4.9781e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.4128 - val_accuracy: 0.7850 - val_loss: 1.0126 - learning_rate: 4.9781e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9939 - loss: 0.3542 - val_accuracy: 0.7944 - val_loss: 1.0147 - learning_rate: 4.9781e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9916 - loss: 0.3504 - val_accuracy: 0.7757 - val_loss: 1.0156 - learning_rate: 4.9781e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.3459 - val_accuracy: 0.8037 - val_loss: 1.0154 - learning_rate: 4.9781e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9805 - loss: 0.3883 - val_accuracy: 0.7944 - val_loss: 1.0105 - learning_rate: 2.4891e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.3586 - val_accuracy: 0.7944 - val_loss: 1.0113 - learning_rate: 2.4891e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9893 - loss: 0.3320 - val_accuracy: 0.8037 - val_loss: 1.0038 - learning_rate: 2.4891e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.3290 - val_accuracy: 0.8131 - val_loss: 1.0030 - learning_rate: 2.4891e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9934 - loss: 0.3242 - val_accuracy: 0.8131 - val_loss: 1.0007 - learning_rate: 2.4891e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.3392 - val_accuracy: 0.8224 - val_loss: 0.9989 - learning_rate: 2.4891e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 0.3240 - val_accuracy: 0.8131 - val_loss: 0.9913 - learning_rate: 2.4891e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.3310 - val_accuracy: 0.8037 - val_loss: 0.9976 - learning_rate: 2.4891e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.3471 - val_accuracy: 0.8037 - val_loss: 1.0027 - learning_rate: 2.4891e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9820 - loss: 0.3257 - val_accuracy: 0.8037 - val_loss: 1.0057 - learning_rate: 2.4891e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9733 - loss: 0.3617 - val_accuracy: 0.7944 - val_loss: 1.0041 - learning_rate: 1.2445e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9964 - loss: 0.3137 - val_accuracy: 0.7944 - val_loss: 1.0072 - learning_rate: 1.2445e-04\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8013 - loss: 0.9951  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 17:28:58,189 - INFO - Test accuracy: 0.7664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-07 17:28:58,764 - INFO - \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.69      0.80      0.74        25\n",
      "     boredom       0.89      0.94      0.91        17\n",
      "     disgust       1.00      0.78      0.88         9\n",
      "        fear       0.78      0.50      0.61        14\n",
      "   happiness       0.50      0.57      0.53        14\n",
      "     neutral       0.81      0.81      0.81        16\n",
      "     sadness       0.92      0.92      0.92        12\n",
      "\n",
      "    accuracy                           0.77       107\n",
      "   macro avg       0.80      0.76      0.77       107\n",
      "weighted avg       0.78      0.77      0.77       107\n",
      "\n",
      "2024-12-07 17:28:58,776 - INFO - Saved final model to /Users/huangjuhua/文档文稿/NYU/Time_Series/results/models/final_model.keras\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from typing import Dict, Tuple, Any, List\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('emotion_recognition.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualization settings\n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 300,\n",
    "    'savefig.dpi': 300,\n",
    "    'figure.figsize': (10, 6),\n",
    "    'font.size': 12,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3\n",
    "})\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for the emotion recognition model\"\"\"\n",
    "    num_classes: int = 7\n",
    "    input_dropout: float = 0.2\n",
    "    l2_lambda: float = 0.01\n",
    "    patience: int = 10\n",
    "    max_trials: int = 20\n",
    "    num_initial_points: int = 5\n",
    "    max_epochs: int = 50\n",
    "    batch_size: int = 32\n",
    "    # Feature selection flags\n",
    "    use_indices: bool = True\n",
    "    use_mps: bool = True\n",
    "    use_vggish: bool = True\n",
    "    use_yamnet: bool = True\n",
    "\n",
    "class EmotionRecognitionModel:\n",
    "    \"\"\"Class to handle emotion recognition model training and evaluation\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 data_path: str,\n",
    "                 output_dir: str,\n",
    "                 config: ModelConfig = ModelConfig()):\n",
    "        \"\"\"\n",
    "        Initialize the emotion recognition model\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to aggregated data pickle file\n",
    "            output_dir: Directory for saving model outputs\n",
    "            config: Model configuration\n",
    "        \"\"\"\n",
    "        self.data_path = Path(data_path)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.config = config\n",
    "        \n",
    "        # Create output directories\n",
    "        self.model_dir = self.output_dir / 'models'\n",
    "        self.plot_dir = self.output_dir / 'plots'\n",
    "        for directory in [self.model_dir, self.plot_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "        # Emotion label mapping\n",
    "        self.label_mapping = {\n",
    "            'anger': 0,\n",
    "            'boredom': 1,\n",
    "            'disgust': 2,\n",
    "            'fear': 3,\n",
    "            'happiness': 4,\n",
    "            'neutral': 5,\n",
    "            'sadness': 6\n",
    "        }\n",
    "        \n",
    "        logging.info(\"Model initialized\")\n",
    "        \n",
    "    def load_and_preprocess_data(self) -> Tuple[Dict[str, np.ndarray], Dict[str, np.ndarray]]:\n",
    "        \"\"\"Load and preprocess the data with configurable feature selection\"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Loading data from {self.data_path}\")\n",
    "            with open(self.data_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "            # Define feature types and their usage flags\n",
    "            feature_types = {\n",
    "                'indices': ('indices_raw_pca', self.config.use_indices),\n",
    "                'mps': ('mps_pca', self.config.use_mps),\n",
    "                'vggish': ('vggish_pca', self.config.use_vggish),\n",
    "                'yamnet': ('yamnet_pca', self.config.use_yamnet)\n",
    "            }\n",
    "            \n",
    "            # Extract and combine selected features\n",
    "            features = {}\n",
    "            for split in ['train', 'valid', 'test']:\n",
    "                selected_features = []\n",
    "                for feature_type, (feature_suffix, use_feature) in feature_types.items():\n",
    "                    if use_feature:\n",
    "                        feature_name = f'{split}_{feature_suffix}'\n",
    "                        if feature_name in data:\n",
    "                            selected_features.append(data[feature_name])\n",
    "                            logging.info(f\"Added {feature_type} features for {split} split: \"\n",
    "                                       f\"shape {data[feature_name].shape}\")\n",
    "                        else:\n",
    "                            logging.warning(f\"Feature {feature_name} not found in data\")\n",
    "                \n",
    "                if not selected_features:\n",
    "                    raise ValueError(\"No features selected for processing\")\n",
    "                    \n",
    "                features[split] = np.concatenate(selected_features, axis=1)\n",
    "                logging.info(f\"Combined {split} features shape: {features[split].shape}\")\n",
    "            \n",
    "            # Process labels\n",
    "            labels = {}\n",
    "            for split in ['train', 'valid', 'test']:\n",
    "                labels[split] = data[f'y_{split}'].map(self.label_mapping).values\n",
    "                logging.info(f\"{split} labels shape: {labels[split].shape}\")\n",
    "                \n",
    "            self._validate_data(features, labels)\n",
    "            return features, labels\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _validate_data(self, \n",
    "                      features: Dict[str, np.ndarray], \n",
    "                      labels: Dict[str, np.ndarray]) -> None:\n",
    "        \"\"\"Validate the loaded data\"\"\"\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            if len(features[split]) != len(labels[split]):\n",
    "                raise ValueError(f\"Mismatch in {split} set sizes\")\n",
    "            \n",
    "            if not np.all(np.isfinite(features[split])):\n",
    "                raise ValueError(f\"Non-finite values in {split} features\")\n",
    "            \n",
    "            unique_labels = np.unique(labels[split])\n",
    "            expected_labels = np.arange(self.config.num_classes)\n",
    "            if not np.array_equal(np.sort(unique_labels), expected_labels):\n",
    "                raise ValueError(f\"Missing classes in {split} set\")\n",
    "\n",
    "    def build_model(self, hp: kt.HyperParameters) -> tf.keras.Model:\n",
    "        \"\"\"Build the model with given hyperparameters\"\"\"\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        # Input layer\n",
    "        model.add(layers.Input(shape=(self.input_shape,)))\n",
    "        \n",
    "        # Initial dropout\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(rate=self.config.input_dropout))\n",
    "        \n",
    "        # Hidden layers\n",
    "        n_layers = hp.Int(\"num_layers\", 1, 5)\n",
    "        for i in range(n_layers):\n",
    "            model.add(layers.Dense(\n",
    "                units=hp.Int(f\"units_{i}\", 16, 512, step=16),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "                kernel_regularizer=regularizers.l2(self.config.l2_lambda)\n",
    "            ))\n",
    "            model.add(layers.BatchNormalization())\n",
    "            model.add(layers.Dropout(rate=hp.Float(f\"dropout_{i}\", 0.0, 0.5)))\n",
    "        \n",
    "        # Output layer\n",
    "        model.add(layers.Dense(self.config.num_classes, activation='softmax'))\n",
    "        \n",
    "        # Compile\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(\n",
    "                learning_rate=hp.Float(\"lr\", 1e-4, 1e-2, sampling=\"log\")\n",
    "            ),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "\n",
    "    def create_callbacks(self) -> List[tf.keras.callbacks.Callback]:\n",
    "        \"\"\"Create training callbacks\"\"\"\n",
    "        return [\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=self.config.patience,\n",
    "                restore_best_weights=True\n",
    "            ),\n",
    "            tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath=str(self.model_dir / 'best_model.keras'),  # Changed from .h5 to .keras\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False  # Save the entire model\n",
    "            ),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-6\n",
    "            ),\n",
    "            tf.keras.callbacks.CSVLogger(\n",
    "                str(self.model_dir / 'training_history.csv'),\n",
    "                separator=',',\n",
    "                append=False\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    # Also, let's add a method to save the model configuration:\n",
    "    def _save_model_config(self, model: tf.keras.Model, hyperparameters: Dict) -> None:\n",
    "        \"\"\"Save model configuration and hyperparameters\"\"\"\n",
    "        config_path = self.model_dir / 'model_config.txt'\n",
    "        with open(config_path, 'w') as f:\n",
    "            # Save model summary\n",
    "            model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "            f.write('\\n\\nHyperparameters:\\n')\n",
    "            for param, value in hyperparameters.items():\n",
    "                f.write(f'{param}: {value}\\n')\n",
    "            \n",
    "\n",
    "    # Update the train_and_evaluate method to include the config saving:\n",
    "    def train_and_evaluate(self) -> None:\n",
    "        \"\"\"Train and evaluate the model\"\"\"\n",
    "        try:\n",
    "            # Load and preprocess data\n",
    "            features, labels = self.load_and_preprocess_data()\n",
    "            self.input_shape = features['train'].shape[1]\n",
    "            \n",
    "            # Create tuner\n",
    "            tuner = kt.BayesianOptimization(\n",
    "                self.build_model,\n",
    "                objective='val_accuracy',\n",
    "                max_trials=self.config.max_trials,\n",
    "                directory=str(self.model_dir),\n",
    "                project_name='emotion_recognition'\n",
    "            )\n",
    "            \n",
    "            # Search for best hyperparameters\n",
    "            logging.info(\"Starting hyperparameter search...\")\n",
    "            tuner.search(\n",
    "                features['train'],\n",
    "                labels['train'],\n",
    "                validation_data=(features['valid'], labels['valid']),\n",
    "                epochs=self.config.max_epochs,\n",
    "                batch_size=self.config.batch_size,\n",
    "                callbacks=self.create_callbacks()\n",
    "            )\n",
    "            \n",
    "            # Get best hyperparameters\n",
    "            best_hps = tuner.get_best_hyperparameters(1)[0]\n",
    "            logging.info(f\"Best hyperparameters: {best_hps.values}\")\n",
    "            \n",
    "            # Build and train final model\n",
    "            best_model = tuner.hypermodel.build(best_hps)\n",
    "            \n",
    "            # Save model configuration\n",
    "            self._save_model_config(best_model, best_hps.values)\n",
    "            \n",
    "            # Train model\n",
    "            history = best_model.fit(\n",
    "                features['train'],\n",
    "                labels['train'],\n",
    "                validation_data=(features['valid'], labels['valid']),\n",
    "                epochs=self.config.max_epochs,\n",
    "                batch_size=self.config.batch_size,\n",
    "                callbacks=self.create_callbacks()\n",
    "            )\n",
    "            \n",
    "            # Evaluate model\n",
    "            self._evaluate_model(best_model, features, labels, history)\n",
    "            \n",
    "            # Save final model\n",
    "            final_model_path = self.model_dir / 'final_model.keras'\n",
    "            best_model.save(final_model_path)\n",
    "            logging.info(f\"Saved final model to {final_model_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _evaluate_model(self, \n",
    "                       model: tf.keras.Model,\n",
    "                       features: Dict[str, np.ndarray],\n",
    "                       labels: Dict[str, np.ndarray],\n",
    "                       history: tf.keras.callbacks.History) -> None:\n",
    "        \"\"\"Evaluate the model and create visualizations\"\"\"\n",
    "        # Plot training history\n",
    "        self._plot_training_history(history)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        test_loss, test_acc = model.evaluate(features['test'], labels['test'])\n",
    "        logging.info(f\"Test accuracy: {test_acc:.4f}\")\n",
    "        \n",
    "        # Generate predictions\n",
    "        y_pred = np.argmax(model.predict(features['test']), axis=1)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        self._plot_confusion_matrix(labels['test'], y_pred)\n",
    "        \n",
    "        # Print classification report\n",
    "        report = classification_report(\n",
    "            labels['test'],\n",
    "            y_pred,\n",
    "            target_names=self.label_mapping.keys()\n",
    "        )\n",
    "        logging.info(f\"\\nClassification Report:\\n{report}\")\n",
    "\n",
    "    def _plot_training_history(self, history: tf.keras.callbacks.History) -> None:\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax1.plot(history.history['accuracy'], label='Train')\n",
    "        ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "        ax1.set_title('Model Accuracy')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Accuracy')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Loss plot\n",
    "        ax2.plot(history.history['loss'], label='Train')\n",
    "        ax2.plot(history.history['val_loss'], label='Validation')\n",
    "        ax2.set_title('Model Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.plot_dir / 'training_history.png')\n",
    "        plt.close()\n",
    "\n",
    "    def _plot_confusion_matrix(self, y_true: np.ndarray, y_pred: np.ndarray) -> None:\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            xticklabels=list(self.label_mapping.keys()),\n",
    "            yticklabels=list(self.label_mapping.keys())\n",
    "        )\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.plot_dir / 'confusion_matrix.png')\n",
    "        plt.close()\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    try:\n",
    "        data_path = \"/Users/huangjuhua/文档文稿/NYU/Time_Series/data/processed/aggregated_data.pkl\"\n",
    "        output_dir = \"/Users/huangjuhua/文档文稿/NYU/Time_Series/results\"\n",
    "        \n",
    "        # Configure which features to use\n",
    "        config = ModelConfig(\n",
    "            max_trials=20,\n",
    "            max_epochs=50,\n",
    "            batch_size=32,\n",
    "            patience=10,\n",
    "            # Feature selection\n",
    "            use_indices=True,\n",
    "            use_mps=True,\n",
    "            use_vggish=True,\n",
    "            use_yamnet=True\n",
    "        )\n",
    "        \n",
    "        # Initialize and run model\n",
    "        model = EmotionRecognitionModel(data_path, output_dir, config)\n",
    "        logging.info(\"Starting model training and evaluation...\")\n",
    "        model.train_and_evaluate()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Processing failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "time_series_finalProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
